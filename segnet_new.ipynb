{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "METAINFO = {\n",
    "    \"classes\": (\n",
    "        \"unlabelled\",\n",
    "        \"asphalt/concrete\",\n",
    "        \"dirt\",\n",
    "        \"mud\",\n",
    "        \"water\",\n",
    "        \"gravel\",\n",
    "        \"other-terrain\",\n",
    "        \"tree-trunk\",\n",
    "        \"tree-foliage\",\n",
    "        \"bush/shrub\",\n",
    "        \"fence\",\n",
    "        \"other-structure\",\n",
    "        \"pole\",\n",
    "        \"vehicle\",\n",
    "        \"rock\",\n",
    "        \"log\",\n",
    "        \"other-object\",\n",
    "        \"sky\",\n",
    "        \"grass\",\n",
    "    ),\n",
    "    \"palette\": [\n",
    "        (0, 0, 0),\n",
    "        (230, 25, 75),\n",
    "        (60, 180, 75),\n",
    "        (255, 225, 25),\n",
    "        (0, 130, 200),\n",
    "        (145, 30, 180),\n",
    "        (70, 240, 240),\n",
    "        (240, 50, 230),\n",
    "        (210, 245, 60),\n",
    "        (250, 190, 190),\n",
    "        (0, 128, 128),\n",
    "        (170, 110, 40),\n",
    "        (255, 250, 200),\n",
    "        (128, 0, 0),\n",
    "        (170, 255, 195),\n",
    "        (128, 128, 0),\n",
    "        (255, 215, 180),\n",
    "        (0, 0, 128),\n",
    "        (128, 128, 128),\n",
    "    ],\n",
    "    \"cidx\": list(range(19))\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = 256  # Resized image size\n",
    "BATCH_SIZE = 8  # Adjust batch size according to available memory\n",
    "NUM_CLASSES = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_sample_data(file_path, sample_fraction=0.1):\n",
    "    df = pd.read_csv(file_path)\n",
    "    sampled_df = df.sample(frac=sample_fraction, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "train_df = load_and_sample_data('train.csv')\n",
    "val_df = load_and_sample_data('val.csv')\n",
    "test_df = load_and_sample_data('test.csv')\n",
    "\n",
    "# Data generators for training and validation\n",
    "def data_generator(df, batch_size, img_size, num_classes):\n",
    "    while True:\n",
    "        for start in range(0, len(df), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + batch_size, len(df))\n",
    "            batch_df = df[start:end]\n",
    "            for _, row in batch_df.iterrows():\n",
    "                img = cv2.imread(row['im_path'])\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (img_size, img_size))\n",
    "                img = img / 255\n",
    "                \n",
    "                label = cv2.imread(row['label_path'], cv2.IMREAD_GRAYSCALE)\n",
    "                label = cv2.resize(label, (img_size, img_size))\n",
    "                label = to_categorical(label, num_classes=num_classes)\n",
    "                \n",
    "                x_batch.append(img)\n",
    "                y_batch.append(label)\n",
    "\n",
    "            yield np.array(x_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data EDA, check unique values in label images, we want to make sure that all classes are in the set of unique values\n",
    "# def check_unique_values(df):\n",
    "#     unique_values = set()\n",
    "#     for _, row in df.iterrows():\n",
    "#         label = cv2.imread(row['label_path'], cv2.IMREAD_GRAYSCALE)\n",
    "#         unique_values.update(np.unique(label))\n",
    "#     return unique_values\n",
    "\n",
    "# train_unique_values = check_unique_values(train_df)\n",
    "# val_unique_values = check_unique_values(val_df)\n",
    "# test_unique_values = check_unique_values(test_df)\n",
    "\n",
    "# print(\"Unique values in train labels:\", train_unique_values)\n",
    "# print(\"Unique values in val labels:\", val_unique_values)\n",
    "# print(\"Unique values in test labels:\", test_unique_values)\n",
    "\n",
    "# Jaccard coefficient and loss\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpool(input, skip_conn, skip_index):\n",
    "    expanded = tf.expand_dims(skip_index, axis=-1)\n",
    "    print(\"indices\", expanded.shape)\n",
    "    print(\"input:\", input.shape)\n",
    "    print(\"Output shape:\", tf.shape(skip_conn))\n",
    "    expanded = tf.scatter_nd(indices=expanded, updates=input, shape=tf.shape(skip_conn))\n",
    "    return expanded\n",
    "\n",
    "def upsample(input, skip_conn, skip_index, nfilters):\n",
    "    u1 = Lambda(lambda x: unpool(x[0], x[1], x[2]))([input, skip_conn, skip_index])\n",
    "    \n",
    "    u1 = Conv2D(nfilters, (3, 3), activation='relu', padding='same')(u1)\n",
    "    cc = concatenate([u1, skip_conn]) # remove?\n",
    "    c1 = Conv2D(nfilters, (3, 3), activation='relu', padding='same')(cc)\n",
    "    c1 = Conv2D(nfilters, (3, 3), activation='relu', padding='same')(c1)\n",
    "    return c1\n",
    "\n",
    "def build_segnet_model(img_size, num_classes):\n",
    "    inputs = Input(shape=(img_size, img_size, 3))\n",
    "\n",
    "    # Downsampling (Encoder)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1, i1 = tf.nn.max_pool_with_argmax(c1, ksize=2, strides=2, padding='SAME', include_batch_in_index=True)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2, i2 = tf.nn.max_pool_with_argmax(c2, ksize=2, strides=2, padding='SAME', include_batch_in_index=True)\n",
    "    \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3, i3 = tf.nn.max_pool_with_argmax(c3, ksize=2, strides=2, padding='SAME', include_batch_in_index=True)\n",
    "    \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4, i4 = tf.nn.max_pool_with_argmax(c4, ksize=2, strides=2, padding='SAME', include_batch_in_index=True)\n",
    "\n",
    "    # Bottleneck\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Upsampling (Decoder)\n",
    "    c6 = upsample(c5, c4, i4, 128)\n",
    "    c7 = upsample(c6, c3, i3, 64)\n",
    "    c8 = upsample(c7, c2, i2, 32)\n",
    "    c9 = upsample(c8, c1, i1, 16)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded indices shape: (None, 16, 16, 128, 1)\n",
      "Updates shape: (None, 16, 16, 256)\n",
      "Output shape: Tensor(\"lambda_6/Shape:0\", shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"lambda_6\" (type Lambda).\n\nInput 'shape' of 'ScatterNd' Op has type int32 that does not match type int64 of argument 'indices'.\n\nCall arguments received by layer \"lambda_6\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 16, 16, 256), dtype=float32)', 'tf.Tensor(shape=(None, 32, 32, 128), dtype=float32)', 'tf.Tensor(shape=(None, 16, 16, 128), dtype=int64)']\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m val_gen \u001b[38;5;241m=\u001b[39m data_generator(val_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Build and compile the model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_segnet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[jacard_coef])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 44\u001b[0m, in \u001b[0;36mbuild_segnet_model\u001b[1;34m(img_size, num_classes)\u001b[0m\n\u001b[0;32m     41\u001b[0m c5 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m256\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(c5)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Upsampling (Decoder)\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m c6 \u001b[38;5;241m=\u001b[39m \u001b[43mupsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m c7 \u001b[38;5;241m=\u001b[39m upsample(c6, c3, i3, \u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m     46\u001b[0m c8 \u001b[38;5;241m=\u001b[39m upsample(c7, c2, i2, \u001b[38;5;241m32\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mupsample\u001b[1;34m(input, skip_conn, skip_index, nfilters)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsample\u001b[39m(\u001b[38;5;28minput\u001b[39m, skip_conn, skip_index, nfilters):\n\u001b[1;32m---> 10\u001b[0m     u1 \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43munpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     u1 \u001b[38;5;241m=\u001b[39m Conv2D(nfilters, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(u1)\n\u001b[0;32m     13\u001b[0m     cc \u001b[38;5;241m=\u001b[39m concatenate([u1, skip_conn])\n",
      "File \u001b[1;32mc:\\Users\\shree\\anaconda3\\envs\\segnet\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mupsample.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsample\u001b[39m(\u001b[38;5;28minput\u001b[39m, skip_conn, skip_index, nfilters):\n\u001b[1;32m---> 10\u001b[0m     u1 \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43munpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)([\u001b[38;5;28minput\u001b[39m, skip_conn, skip_index])\n\u001b[0;32m     12\u001b[0m     u1 \u001b[38;5;241m=\u001b[39m Conv2D(nfilters, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(u1)\n\u001b[0;32m     13\u001b[0m     cc \u001b[38;5;241m=\u001b[39m concatenate([u1, skip_conn])\n",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m, in \u001b[0;36munpool\u001b[1;34m(input, skip_conn, skip_index)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdates shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39mshape(skip_conn))\n\u001b[1;32m----> 6\u001b[0m expanded \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskip_conn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expanded\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer \"lambda_6\" (type Lambda).\n\nInput 'shape' of 'ScatterNd' Op has type int32 that does not match type int64 of argument 'indices'.\n\nCall arguments received by layer \"lambda_6\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 16, 16, 256), dtype=float32)', 'tf.Tensor(shape=(None, 32, 32, 128), dtype=float32)', 'tf.Tensor(shape=(None, 16, 16, 128), dtype=int64)']\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "train_gen = data_generator(train_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n",
    "val_gen = data_generator(val_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_segnet_model(IMG_SIZE, NUM_CLASSES)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[jacard_coef])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_gen, steps_per_epoch=len(train_df) // BATCH_SIZE, epochs=10, validation_data=val_gen, validation_steps=len(val_df) // BATCH_SIZE)\n",
    "\n",
    "# Evaluate the model\n",
    "test_gen = data_generator(test_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n",
    "model.evaluate(test_gen, steps=len(test_df) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a sample image\n",
    "sample_image, sample_mask = next(data_generator(test_df, 1, IMG_SIZE, NUM_CLASSES))\n",
    "prediction = model.predict(sample_image)[0]\n",
    "\n",
    "palette = METAINFO['palette']\n",
    "def label_to_rgb(label, palette):\n",
    "    rgb_image = np.zeros((*label.shape, 3), dtype=np.uint8)\n",
    "    for label_idx, color in enumerate(palette):\n",
    "        rgb_image[label == label_idx] = color\n",
    "    return rgb_image\n",
    "\n",
    "sample_image, sample_mask = next(data_generator(test_df, 1, IMG_SIZE, NUM_CLASSES))\n",
    "prediction = model.predict(sample_image)[0]\n",
    "\n",
    "def label_to_rgb(label, palette):\n",
    "    rgb_image = np.zeros((*label.shape, 3), dtype=np.uint8)\n",
    "    for label_idx, color in enumerate(palette):\n",
    "        rgb_image[label == label_idx] = color\n",
    "    return rgb_image\n",
    "\n",
    "# visualize the sample image, ground truth and prediction\n",
    "sample_image = sample_image[0]\n",
    "sample_mask = sample_mask[0]\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(131)\n",
    "plt.imshow(sample_image)\n",
    "plt.title(\"Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(label_to_rgb(sample_mask.argmax(axis=2), palette))\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(label_to_rgb(prediction.argmax(axis=2), palette))\n",
    "plt.title(\"Prediction\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IoU for each class\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "def calculate_class_iou(y_true, y_pred, num_classes):\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        true_class = (y_true == cls)\n",
    "        pred_class = (y_pred == cls)\n",
    "        \n",
    "        intersection = np.logical_and(true_class, pred_class).sum()\n",
    "        union = np.logical_or(true_class, pred_class).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = np.nan  # If there is no ground truth or prediction for this class, set IoU to NaN\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        \n",
    "        ious.append(iou)\n",
    "    \n",
    "    return ious\n",
    "\n",
    "# Function to calculate IoUs for each class\n",
    "def calculate_class_ious(model, test_df, img_size, num_classes):\n",
    "    test_gen = data_generator(test_df, 1, img_size, num_classes)\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    \n",
    "    for _ in range(len(test_df)):\n",
    "        test_images, test_labels = next(test_gen)\n",
    "        y_pred = model.predict(test_images)\n",
    "        y_preds.append(y_pred)\n",
    "        y_trues.append(test_labels)\n",
    "        \n",
    "    y_preds = np.concatenate(y_preds, axis=0)\n",
    "    y_trues = np.concatenate(y_trues, axis=0)\n",
    "    \n",
    "    y_pred_argmax = np.argmax(y_preds, axis=3)\n",
    "    y_true_argmax = np.argmax(y_trues, axis=3)\n",
    "    \n",
    "    class_ious = calculate_class_iou(y_true_argmax, y_pred_argmax, num_classes)\n",
    "    return class_ious\n",
    "\n",
    "# Calculate and print IoU for each class\n",
    "class_ious = calculate_class_ious(model, test_df, IMG_SIZE, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = palette = METAINFO['classes']\n",
    "merged_classes = []\n",
    "merged_ious = []\n",
    "\n",
    "for idx, class_name in enumerate(classes):\n",
    "    if class_name == \"pole\":\n",
    "        # Merge pole IoU into other-object\n",
    "        other_object_idx = classes.index(\"other-object\")\n",
    "        class_ious[other_object_idx] += class_ious[idx]\n",
    "    elif class_name == \"asphalt\":\n",
    "        # Merge asphalt IoU into other-terrain\n",
    "        other_terrain_idx = classes.index(\"other-terrain\")\n",
    "        class_ious[other_terrain_idx] += class_ious[idx]\n",
    "    elif class_name not in [\"vehicle\", \"pole\", \"asphalt\", \"unlabelled\"]:\n",
    "        merged_classes.append(class_name)\n",
    "        merged_ious.append(class_ious[idx])\n",
    "\n",
    "class_iou_pairs = list(zip(merged_classes, merged_ious))\n",
    "sorted_class_iou_pairs = sorted(class_iou_pairs, key=lambda x: x[0])\n",
    "\n",
    "for class_name, iou in sorted_class_iou_pairs:\n",
    "    print(f\"Class {class_name} IoU: {iou * 100: .2f}\")\n",
    "\n",
    "MIou = np.nanmean(merged_ious)\n",
    "print(f\"Mean IoU: {MIou * 100: .2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
