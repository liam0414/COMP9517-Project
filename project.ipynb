{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in train labels: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}\n",
      "Unique values in val labels: {2, 3, 5, 6, 7, 8, 9, 11, 14, 15, 16, 17, 18}\n",
      "Unique values in test labels: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18}\n",
      "Epoch 1/10\n",
      "378/378 [==============================] - 198s 522ms/step - loss: 2.0298 - accuracy: 0.3750 - val_loss: 1.5149 - val_accuracy: 0.5136\n",
      "Epoch 2/10\n",
      "378/378 [==============================] - 196s 521ms/step - loss: 1.6688 - accuracy: 0.4655 - val_loss: 1.4012 - val_accuracy: 0.5521\n",
      "Epoch 3/10\n",
      "378/378 [==============================] - 197s 521ms/step - loss: 1.5380 - accuracy: 0.5092 - val_loss: 1.3732 - val_accuracy: 0.5710\n",
      "Epoch 4/10\n",
      "378/378 [==============================] - 203s 537ms/step - loss: 1.4895 - accuracy: 0.5215 - val_loss: 1.3645 - val_accuracy: 0.5792\n",
      "Epoch 5/10\n",
      "378/378 [==============================] - 191s 505ms/step - loss: 1.4601 - accuracy: 0.5285 - val_loss: 1.3651 - val_accuracy: 0.5828\n",
      "Epoch 6/10\n",
      "378/378 [==============================] - 190s 504ms/step - loss: 1.4396 - accuracy: 0.5322 - val_loss: 1.3753 - val_accuracy: 0.5804\n",
      "Epoch 7/10\n",
      "378/378 [==============================] - 190s 504ms/step - loss: 1.4336 - accuracy: 0.5361 - val_loss: 1.3289 - val_accuracy: 0.5921\n",
      "Epoch 8/10\n",
      "378/378 [==============================] - 190s 503ms/step - loss: 1.4203 - accuracy: 0.5402 - val_loss: 1.3220 - val_accuracy: 0.5937\n",
      "Epoch 9/10\n",
      "378/378 [==============================] - 190s 503ms/step - loss: 1.3905 - accuracy: 0.5483 - val_loss: 1.3271 - val_accuracy: 0.5969\n",
      "Epoch 10/10\n",
      "378/378 [==============================] - 189s 500ms/step - loss: 1.3772 - accuracy: 0.5519 - val_loss: 1.3168 - val_accuracy: 0.6003\n",
      "266/266 [==============================] - 128s 482ms/step - loss: 1.4166 - accuracy: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4166265726089478, 0.5624714493751526]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load and sample data\n",
    "def load_and_sample_data(file_path, sample_fraction=1):\n",
    "    df = pd.read_csv(file_path)\n",
    "    sampled_df = df.sample(frac=sample_fraction, random_state=42)  # Sample 1% of the data\n",
    "    return sampled_df\n",
    "\n",
    "# step 1, load csv files, \n",
    "# TODO: to make sure we are loading data from 5 folders, and we need to make sure the images\n",
    "# have all the 15 classes\n",
    "train_df = load_and_sample_data('train.csv', 0.5)\n",
    "val_df = load_and_sample_data('val.csv')\n",
    "test_df = load_and_sample_data('test.csv')\n",
    "\n",
    "# Check unique values in label images\n",
    "# step 1, check the unique values in the label images\n",
    "def check_unique_values(df):\n",
    "    unique_values = set()\n",
    "    for _, row in df.iterrows():\n",
    "        label = cv2.imread(row['label_path'], cv2.IMREAD_GRAYSCALE)\n",
    "        unique_values.update(np.unique(label))\n",
    "    return unique_values\n",
    "\n",
    "train_unique_values = check_unique_values(train_df)\n",
    "val_unique_values = check_unique_values(val_df)\n",
    "test_unique_values = check_unique_values(test_df)\n",
    "\n",
    "print(\"Unique values in train labels:\", train_unique_values)\n",
    "print(\"Unique values in val labels:\", val_unique_values)\n",
    "print(\"Unique values in test labels:\", test_unique_values)\n",
    "\n",
    "# Update NUM_CLASSES based on unique values\n",
    "NUM_CLASSES = len(train_unique_values.union(val_unique_values).union(test_unique_values))\n",
    "\n",
    "# Function to map labels to valid class indices\n",
    "def map_labels(label, num_classes):\n",
    "    label_mapped = np.zeros_like(label)\n",
    "    for i, unique_val in enumerate(np.unique(label)):\n",
    "        if i < num_classes:\n",
    "            label_mapped[label == unique_val] = i\n",
    "        else:\n",
    "            label_mapped[label == unique_val] = 0  # Map unexpected values to background class\n",
    "    return label_mapped\n",
    "\n",
    "# Data generators for training and validation\n",
    "def data_generator(df, batch_size, img_size, num_classes):\n",
    "    while True:\n",
    "        for start in range(0, len(df), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(df))\n",
    "            batch_df = df[start:end]\n",
    "            for _, row in batch_df.iterrows():\n",
    "                img = cv2.imread(row['im_path'])\n",
    "                img = cv2.resize(img, (img_size, img_size))\n",
    "                img = img / 255.0\n",
    "                \n",
    "                label = cv2.imread(row['label_path'], cv2.IMREAD_GRAYSCALE)\n",
    "                label = cv2.resize(label, (img_size, img_size))\n",
    "                label = map_labels(label, num_classes)\n",
    "                label = to_categorical(label, num_classes=num_classes)\n",
    "                \n",
    "                x_batch.append(img)\n",
    "                y_batch.append(label)\n",
    "            yield np.array(x_batch), np.array(y_batch)\n",
    "\n",
    "# Custom IoU metric\n",
    "def iou_metric(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) - intersection\n",
    "    iou = tf.reduce_mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "# Custom Jaccard index\n",
    "def jaccard_index(y_true, y_pred, smooth=1e-6):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) - intersection\n",
    "    jaccard = tf.reduce_mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return jaccard\n",
    "\n",
    "# U-Net Model\n",
    "def build_unet_model(img_size, num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    # Downsampling\n",
    "    c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    # Upsampling\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(c9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = 256  # Resized image size\n",
    "BATCH_SIZE = 8  # Adjust batch size according to available memory\n",
    "\n",
    "# Create data generators\n",
    "train_gen = data_generator(train_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n",
    "val_gen = data_generator(val_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_unet_model(IMG_SIZE, NUM_CLASSES)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_gen, steps_per_epoch=len(train_df) // BATCH_SIZE, epochs=10, validation_data=val_gen, validation_steps=len(val_df) // BATCH_SIZE)\n",
    "\n",
    "# Evaluate the model\n",
    "test_gen = data_generator(test_df, BATCH_SIZE, IMG_SIZE, NUM_CLASSES)\n",
    "model.evaluate(test_gen, steps=len(test_df) // BATCH_SIZE)\n",
    "\n",
    "# Predict on a sample image\n",
    "sample_image, sample_mask = next(data_generator(test_df, 1, IMG_SIZE, NUM_CLASSES))\n",
    "prediction = model.predict(sample_image)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43msample_image\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(sample_image[0])\n",
    "plt.title('Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(np.argmax(sample_mask[0], axis=-1))\n",
    "plt.title('True Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.argmax(prediction, axis=-1))\n",
    "plt.title('Predicted Mask')\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
